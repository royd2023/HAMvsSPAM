{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royd2023/HAMvsSPAM/blob/main/fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip uninstall -y tensorflow tf-nightly\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Data"
      ],
      "metadata": {
        "id": "u0B-PrmW-Pq3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "def load_tsv_file(file_path):\n",
        "  labels = []\n",
        "  data = []\n",
        "\n",
        "  try:\n",
        "        df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "        labels = df['label'].tolist()\n",
        "        data = df['message'].tolist()\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error reading file with pandas: {e}\")\n",
        "\n",
        "      # Method 2: Manual parsing as fallback\n",
        "      try:\n",
        "          with open(file_path, 'r', encoding='utf-8') as file:\n",
        "              for line in file:\n",
        "                  line = line.strip()\n",
        "                  if line:  # Skip empty lines\n",
        "                      parts = line.split('\\t', 1)  # Split on first tab only\n",
        "                      if len(parts) == 2:\n",
        "                          label, message = parts\n",
        "                          labels.append(label)\n",
        "                          data.append(message)\n",
        "      except Exception as e2:\n",
        "          print(f\"Error with manual parsing: {e2}\")\n",
        "          return [], []\n",
        "\n",
        "  return labels, data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "labels, data = load_tsv_file(train_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have separated the labels and data, we can vectorize the data."
      ],
      "metadata": {
        "id": "NDaGqynU-VsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=10000)  # Use top 10k words\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "# Convert messages to sequences of numbers\n",
        "x = tokenizer.texts_to_sequences(data)\n",
        "x = pad_sequences(x, maxlen=100)  # Pad to same length (100 words)\n",
        "\n",
        "# Convert labels to binary (0 for ham, 1 for spam)\n",
        "y = [1 if label == 'spam' else 0 for label in labels]"
      ],
      "metadata": {
        "id": "kuj6VcaW-cnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  x = sequence of integers (each message is now a list of numbers)\n",
        "*  y = labels 0 for ham and 1 for spam"
      ],
      "metadata": {
        "id": "0GdN6m5d-pp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets split the data into training and testing sets"
      ],
      "metadata": {
        "id": "UGOa_FSI_VOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data before splitting\n",
        "indices = np.random.permutation(len(x))\n",
        "x_shuffled = x[indices]\n",
        "y_shuffled = [y[i] for i in indices]\n",
        "\n",
        "\n",
        "x = tf.constant(x)\n",
        "y = tf.constant(y)\n",
        "\n",
        "dataset_size = len(x)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "x_train = x[:train_size]\n",
        "x_test = x[train_size:]\n",
        "y_train = y[:train_size]\n",
        "y_test = y[train_size:]\n"
      ],
      "metadata": {
        "id": "yGeAFqb4_QHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Model"
      ],
      "metadata": {
        "id": "7shTOXeHAEaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    Embedding(10000, 16, input_length=100),  # Word embeddings\n",
        "    GlobalAveragePooling1D(),               # Average the embeddings\n",
        "    Dense(16, activation='relu'),           # Hidden layer\n",
        "    Dense(1, activation='sigmoid')          # Output layer (0 or 1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "zJF03YOpAD33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model"
      ],
      "metadata": {
        "id": "bWaqY7ZFAeSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# make predictions\n",
        "predictions = model.predict(x_test)\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "# See some results\n",
        "for i in range(5):\n",
        "    actual = \"spam\" if y_test[i] == 1 else \"ham\"\n",
        "    predicted = \"spam\" if predicted_classes[i] == 1 else \"ham\"\n",
        "    confidence = predictions[i][0]\n",
        "    print(f\"Actual: {actual}, Predicted: {predicted}, Confidence: {confidence:.3f}\")"
      ],
      "metadata": {
        "id": "400cmjDZAfmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "\n",
        " # Preprocess the text (same as training data)\n",
        "    sequence = tokenizer.texts_to_sequences([pred_text])\n",
        "    padded = pad_sequences(sequence, maxlen=100)\n",
        "\n",
        "    # Get prediction probability\n",
        "    prediction_prob = float(model.predict(padded)[0][0])\n",
        "\n",
        "    # Convert to label\n",
        "    label = 'spam' if prediction_prob > 0.5 else 'ham'\n",
        "\n",
        "    return [prediction_prob, label]\n",
        "\n",
        "pred_text = \"sale today! to stop texts call 98912460324\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}